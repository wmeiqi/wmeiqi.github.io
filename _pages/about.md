---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# About Me

I am **Meiqi Wu <font face="æ¥·ä½“">(æ­¦ç¾å¥‡)</font>**, a Ph.D. student at **<a herf="https://english.ucas.ac.cn/">University of Chinese Academy of Sciences (UCAS, ä¸­å›½ç§‘å­¦é™¢å¤§å­¦)</a>**, supervised by **<a href="https://people.ucas.ac.cn/~wqwang?language=en">Prof. Weiqiang Wang</a>**. I received my masterâ€™s degree from **<a href="http://english.ia.cas.cn/">Institute of Automation, Chinese Academy of Sciences (CASIA, ä¸­å›½ç§‘å­¦é™¢è‡ªåŠ¨åŒ–ç ”ç©¶æ‰€)</a>** and **<a herf="https://english.ucas.ac.cn/">University of Chinese Academy of Sciences (UCAS, ä¸­å›½ç§‘å­¦é™¢å¤§å­¦)</a>**, supervised by **<a href="https://people.ucas.ac.cn/~huangkaiqi?language=en">Prof. Kaiqi Huang</a>** (IAPR Fellow, IEEE Senior Member). 


<!-- Iâ€™m currently a Ph.D. student in Computer Science advised by Prof. Weiqiang Wang, at CVMT Laboratory, School of Computer Science and Technology, University of Chinese Academy of Sciences. Iâ€™m always open to possible cooperation or visiting opportunities. If you are interested, please contact me by email. -->

My research interest includes computer vision and human-computer interaction. Iâ€™m always open to possible cooperation or visiting opportunities. If you are interested, please contact me by email.
<!--I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->


# ğŸ”¥ News
- **2024.04**:&nbsp;ğŸ“£ğŸ“£ We will present our work (**Global Instance Tracking**) at **TPAMI2023** during the [**VALSE2024**](http://www.valser.org/2024/#/) poster session (May 2024, Chongqing, China) and extend a warm invitation to colleagues interested in visual object/language tracking, evaluation methodologies, and human-computer interaction to engage in discussions with us (see our [**Poster**](https://xuchen-li.github.io/files/VALSE24Poster-364.pdf) for more information).
- **2024.04**:&nbsp;ğŸ‰ğŸ‰ One [**paper**](https://xuchen-li.github.io/#DTLLM) has been accepted by **the 3rd CVPR Workshop on Vision Datasets Understanding and DataCV Challenge** as **Oral Presentation** (CVPRW, Workshop in CCF-A Conference, Oral)!
- **2024.04**:&nbsp;ğŸ‰ğŸ‰ One first author paper has been accepted by IEEE Transactions on Circuits and Systems for Video Technology (TCSVT, CCF-B Journal, IF=8.4).
- **2023.09**:&nbsp;ğŸ‰ğŸ‰ One paper has been accepted by the 37th Conference on Neural Information Processing Systems (NeurIPS, CCF-A Conference, Poster).

   <!-- - *2024.04*: &nbsp;&nbsp;ğŸ‰ğŸ‰ ğŸ“£ğŸ“£We will present our work (Global Instance Tracking (GIT)) at TPAMI2023 during the VALSE2024 poster session (May 2024, Chongqing, China) and extend a warm invitation to colleagues interested in object tracking, evaluation methodologies, and human-computer interaction to engage in discussions with us (see our ğŸª§ Poster for more information). - *2024.04*: &nbsp;ğŸ‰ğŸ‰ One paper has been accepted by the 3rd Workshop on Vision Datasets Understanding and DataCV Challenge in CVPR 2024 (CVPRW, Workshop in CCF-A Conference, Oral). -->

# ğŸ“ Publications 

## âœ… Acceptance
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TCSVT 2024</div><img src='images/AWCV.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
<span class='anchor' id='AWCV'></span>
  
**Finger in Camera Speaks Everything: Unconstrained Air-Writing for Real-World**

<a herf = "https://github.com/wmeiqi"> **<font color='FireBrick'>Meiqi Wu</font>** </a>, [Kaiqi Huang](https://people.ucas.ac.cn/~huangkaiqi?language=en), [Yuanqiang Cai](https://teacher.bupt.edu.cn/caiyuanqiang/zh_CN/index.htm), [Shiyu Hu](https://huuuuusy.github.io/), [Yuzhong Zhao](https://callsys.github.io/zhaoyuzhong.github.io-main/), [Weiqiang Wang](https://people.ucas.ac.cn/~wqwang?language=en)

TCSVT 2024 (CCF-B Journal, IF=8.4): **[IEEE Transactions on Circuits and Systems for Video Technology](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76)**<br>
</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPRW 2024</div><img src='images/DTLLM.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
<span class='anchor' id='DTLLM'></span>
  
**DTLLM-VLT: Diverse Text Generation for Visual Language Tracking Based on LLM**

[Xuchen Li](https://xuchen-li.github.io/), [Xiaokun Feng](https://github.com/XiaokunFeng), [Shiyu Hu](https://huuuuusy.github.io/), <a herf = "https://github.com/wmeiqi"> **<font color='FireBrick'>Meiqi Wu</font>** </a>, Dailing Zhang, Jing Zhang, [Kaiqi Huang](https://people.ucas.ac.cn/~huangkaiqi?language=en)

CVPRW 2024 Oral (Workshop in CCF-A Conference, Oral): **[the 3rd CVPR Workshop on Vision Datasets Understanding and DataCV Challenge](https://sites.google.com/view/vdu-cvpr24/)**<br>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2023</div><img src='images/MGIT.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
<span class='anchor' id='MGIT'></span>
  
**A Multi-modal Global Instance Tracking Benchmark (MGIT): Better Locating Target in Complex Spatio-temporal and Causal Relationship**

[Shiyu Hu](https://huuuuusy.github.io/), Dailing Zhang, <a herf = "https://github.com/wmeiqi"> **<font color='FireBrick'>Meiqi Wu</font>** </a>, [Xiaokun Feng](https://github.com/XiaokunFeng), [Xuchen Li](https://xuchen-li.github.io/), [Xin Zhao](https://www.xinzhaoai.com/), [Kaiqi Huang](https://people.ucas.ac.cn/~huangkaiqi?language=en)

NeurIPS 2023 (CCF-A Conference, Poster): **[the 37th Conference on Neural Information Processing Systems](https://neurips.cc/Conferences/2023)**<br>
  [[**Paper**](https://xuchen-li.github.io/files/MGIT.pdf)]
  [[**BibTeX**](https://xuchen-li.github.io/files/MGIT.bib)]
  [[**Poster**](https://xuchen-li.github.io/files/MGIT-poster.pdf)]
  [[**Slides**](https://xuchen-li.github.io/files/MGIT-Slides.pdf)]
  [[**Platform**](http://videocube.aitestunion.com/)]
  [[**Toolkit**](https://github.com/huuuuusy/videocube-toolkit)]
  [[**Dataset**](http://videocube.aitestunion.com/downloads)]
</div>
</div>

## â˜‘ï¸ Ongoing Research

<div class='paper-box'><div class='paper-box-image'><div><div class="badge-under-review">TCSVT 2024</div><img src='../../images/SOI.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span class='anchor' id='SOI'></span>

**Target or Distractor? Rethinking Similar Object Interference in Single Object Tracking**<br>
[Y. Wang](https://github.com/updateforever), ***<font color=DarkRed>Shiyu Hu</font>***, D. Zhang, [M. Wu](https://github.com/wmeiqi), [T. Yao](http://tingyao.deepfun.club/), [Y. Wang](https://scholar.google.com/citations?user=3nMDEBYAAAAJ), [L. Chen](https://sie.bit.edu.cn/szdw/jsml/ldjsyjsj/zgzcl/06c26b3ebaae4db981aaa388c660c8b5.htm), [X. Zhao](https://www.xinzhaoai.com/) <br>
*[IEEE Transactions on Circuits and Systems for Video Technology](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76) (CCF-B Journal, IF=8.4, Under Review)*<br>
ğŸ“Œ Visual Object Tracking ğŸ“Œ Similar Object Interference ğŸ“Œ Data Mining<br>

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge-under-review">NeurIPS 2024</div><img src='../../images/MemVLT.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span class='anchor' id='MemVLT'></span>

**Remembering Target More Like Humans: A Robust Visual-Language Tracker with Adaptive Prompts**<br>
[X. Feng](https://github.com/XiaokunFeng), [X. Li](https://xuchen-li.github.io/), ***<font color=DarkRed>Shiyu Hu</font>***, D. Zhang, [M. Wu](https://github.com/wmeiqi), [X. Chen](http://www.crise.ia.ac.cn/teachers_view.aspx?TypeId=141&Id=467&Fid=t26:141:26), [K. Huang](https://people.ucas.ac.cn/~huangkaiqi)  <br>
*[the 38th Conference on Neural Information Processing Systems](https://neurips.cc/) (CCF-A Conference, Under Review)*<br>
ğŸ“Œ Visual Language Tracking ğŸ“Œ Human-like Memory Modeling ğŸ“Œ Adaptive Prompts<br>

</div>
</div>



# ğŸ“ Patent

# ğŸ“ Software copyright

# ğŸ– Honors and Awards
* 2019, 2020, 2021, 2022, 2023 **Merit Student of University of Chinese Academy of Sciences (<font face="æ¥·ä½“">ä¸­å›½ç§‘å­¦é™¢å¤§å­¦ä¸‰å¥½å­¦ç”Ÿ</font>)**
* 2019 **National Third Prize**, <a herf="http://ucasstar.sie.ac.cn"> Chinese Academy of Sciences University (UCAS) Cup Innovation and Entrepreneurship Competition</a>
* 2018 **Outstanding Graduates of Shandong Province (<font face="æ¥·ä½“">å±±ä¸œçœä¼˜ç§€æ¯•ä¸šç”Ÿ</font>)**
* 2018 **Outstanding Graduates of Shandong University of Sicence and Technology (<font face="æ¥·ä½“">å±±ä¸œç§‘æŠ€å¤§å­¦ä¼˜ç§€æ¯•ä¸šç”Ÿ</font>)**
* 2018 **Top-notch scientific and technological innovation talents of Shandong University of Science and Technology (<font face="æ¥·ä½“">å±±ä¸œç§‘æŠ€å¤§å­¦ç§‘æŠ€åˆ›æ–°æ‹”å°–äººæ‰</font>)**
* 2017 **National First Prize**, MathorCup College Student Mathematical Modeling Challenge
* 2017 **National Second Prize**, "Certification Cup" Mathematics China Mathematical Modeling Network Challenge
* 2017 **Honourable Metion**, Mathematical Contest In Modeling
* 2016 **National Third Prize**, APMCM Asia-Pacific College Student Mathematical Modeling Competition
* 2016 **National Third Prize**, the 14th Qilu Software Design Competition
* 2016 **National Third Prize**, Qingdao College Mathematical Modeling Invitational Competition
* 2016 **National Encouragement scholarship (<font face="æ¥·ä½“">å›½å®¶åŠ±å¿—å¥–å­¦é‡‘</font>)**
* 2016 **Blu-ray Scholarship (<font face="æ¥·ä½“">è“å…‰å¥–å­¦é‡‘</font>)**
* 2015 **Outstanding Volunteer (<font face="æ¥·ä½“">ä¼˜ç§€å¿—æ„¿è€…</font>)**
* 2015 **Outstanding cadres of Student Association (<font face="æ¥·ä½“">å­¦ç”Ÿåä¼šä¼˜ç§€å¹²äº‹</font>)**
* 2015, 2016, 2017, 2018 **The First Prize Scholarship (<font face="æ¥·ä½“">ä¸€ç­‰å¥–å­¦é‡‘</font>)**
* 2015, 2016, 2017, 2018 **Excellent League Member of Shandong University of Sicence and Technology (<font face="æ¥·ä½“">å±±ä¸œç§‘æŠ€å¤§å­¦ä¼˜ç§€å…±é’å›¢å‘˜</font>)**
* 2015, 2016, 2017, 2018 **Merit Student of Shandong University of Sicence and Technology (<font face="æ¥·ä½“">å±±ä¸œç§‘æŠ€å¤§å­¦ä¸‰å¥½å­¦ç”Ÿ</font>)**

<!--* **China National Scholarship (<font face="æ¥·ä½“">æœ¬ç§‘ç”Ÿå›½å®¶å¥–å­¦é‡‘</font>)**, My Rank: 1/455 (0.22%), at BUPT, by Ministry of Education of China, 2023
* **China National Scholarship (<font face="æ¥·ä½“">æœ¬ç§‘ç”Ÿå›½å®¶å¥–å­¦é‡‘</font>)**, My Rank: 2/430 (0.47%), at BUPT, by Ministry of Education of China, 2022
* **Huawei AI Education Base Scholarship (<font face="æ¥·ä½“">åä¸ºæ™ºèƒ½åŸºåº§å¥–å­¦é‡‘</font>)**, at BUPT, by Ministry of Education of China and Huawei AI Education Base Joint Working Group, 2022
* **Beijing Merit Student (<font face="æ¥·ä½“">åŒ—äº¬å¸‚ä¸‰å¥½å­¦ç”Ÿ</font>)**, at BUPT, by Beijing Municipal Education Commission, 2023
* **College Scholarship of University of Chinese Academy of Sciences (<font face="æ¥·ä½“">ä¸­å›½ç§‘å­¦é™¢å¤§å­¦å¤§å­¦ç”Ÿå¥–å­¦é‡‘</font>)**, at CASIA, by University of Chinese Academy of Sciences, 2023
* **China National Encouragement Scholarship**, My Rank: 8/522 (1.53%), at BUPT, by Ministry of Education of China, 2021
* **Haohan Scholarship and Grants**, at BUPT, by Beijing Haohan DATA Technology Co., Ltd, 2021
* **National First Prize**, China Collegiate Computing Contest-Artificial Intelligence Innovation Contest (team leader), 2022
* **Meritorious Winner**, Mathematical Contest in Modeling and Interdisciplinary Contest in Modeling, 2022
* **National Third Prize**, Huawei Information and Communication Technology Competition Nationwide Final (team leader), 2023
* **National Third Prize**, China Robotics and Artificial Intelligence Competition, 2023
* **National Level Project**, College Students' Innovation and Entrepreneurship Training Program (team leader), 2023
* **National Level Project**, College Students' Innovation and Entrepreneurship Training Program, 2023-->

# ğŸ“– Educations

**2021.09 -** : Ph.D. in [University of Chinese Academy of Sciences (UCAS)](https://english.ucas.ac.cn/)
* **Major:** Computer Applied Technology
* **Supervisor:** [Prof. Weiqiang Wang](https://people.ucas.edu.cn/~wqwang) (ACM Member, IEEE Member)
* **Thesis Title:** Researches of Video-based Air-Writing Dataset Construction and Recognition Algorithm

**2018.09 - 2021.06** : M.S. in [Institute of Automation, Chinese Academy of Sciences (CASIA)](http://english.ia.cas.cn/) and [University of Chinese Academy of Sciences (UCAS)](https://english.ucas.ac.cn/)
- **Major:** Computer Applied Technology
- **Supervisor:** [Prof. Kaiqi Huang](https://people.ucas.ac.cn/~huangkaiqi) (IAPR Fellow, IEEE Senior Member)
- **Thesis Title:** Research of Artificial Intelligence for Psychology
- **Thesis Defense Grade:** Excellent

**2014.09 - 2018.06** : B.E. in College of Computer Science and Engineering, [Shandong University of Science and Technology (SDUST)](https://en.sdust.edu.cn/)
- **Major:** Software Engineering
  
**2015.09 - 2018.06** : B.A. in College of Economics & Management, [Shandong University of Science and Technology (SDUST)](https://en.sdust.edu.cn/)
- **Minor:** Accounting
  

<!--# ğŸ’¬ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)-->


# ğŸ”— For More Info
- [Intelligence of Human-Computer Competition](http://turingai.ia.ac.cn/)
- [Research Group of Intelligent Gaming](http://www.ig.ia.ac.cn:81/)
- [Center for Research on Intelligent System and Engineering (CRISE)](http://www.crise.ia.ac.cn/)
- [Institute of Automation, Chinese Academy of Sciences (CASIA)](http://www.ia.cas.cn/)
- [University of Chinese Academy of Sciences (UCAS)](https://www.ucas.ac.cn/)
- [School of Computer Science and Tenchnology, University of Chinese Academy of Sciences (UCAS)](https://scce.ucas.ac.cn/)

<span class='anchor' id='collaborators'></span>

# ğŸ¤ Collaborators

> I am honored to collaborate with these outstanding researchers. We engage in close discussions concerning various fields such as computer vision, cognitive science, AI4Science, and human-computer interaction. If you are interested in these areas as well, please feel free to contact me.

- [**Shiyu Hu**](https://github.com/huuuuusy), Ph.D. student at the [University of Chinese Academy of Sciences (UCAS)](https://www.ucas.ac.cn/), focusing on computer vision, intelligent evaluation technique, and human-computer interaction.
- [**Yuzhong Zhao**](https://github.com/callsys), Ph.D. student at the [University of Chinese Academy of Sciences (UCAS)](https://www.ucas.ac.cn/), focusing on computer vision
- [**Yuanqiang Cai**](https://teacher.bupt.edu.cn/caiyuanqiang/zh_CN/index.htm) is a Lecturer (University) and Master Tutor at the State Key Laboratory Of Networking And Switching Technology, Beijing University of Posts and Telecommunications and at the School of Computer Science, Beijing University of Posts and Telecommunications.
- [**Xuchen Li**](https://xuchen-li.github.io/), B.E. student at [Beijing University of Posts and Telecommunications (BUPT)](https://xuchen-li.github.io/) and incoming Ph.D. student at the [Institute of Automation, Chinese Academy of Sciences (CASIA)](http://www.ia.cas.cn/), focusing on visual object tracking, visual language tracking and AI4Science.
- **Fangchao Liu**, Ph.D. student at the [Hong Kong University of Science and Technology (HKUST)](https://hkust.edu.hk/zh-hant), focusing on computer vision and AI4Science.
- **Di Shang**, Ph.D. student at the [Institute of Automation, Chinese Academy of Sciences (CASIA)](http://www.ia.cas.cn/), focusing on computer vision, spiking neural network and few-shot learning.
- **Yaxuan Kang**, design researcher, research assistant and interaction designer at the [Institute of Automation, Chinese Academy of Sciences (CASIA)](http://www.ia.cas.cn/), focusing on human-computer interaction.
- [**Yipei Wang**](https://github.com/updateforever), M.S. and incoming Ph.D. student at the [Southeast University](https://www.seu.edu.cn/), focusing on visual object tracking and recommendation system.
- [**Xiaokun Feng**](https://github.com/XiaokunFeng), Ph.D. student at the [Institute of Automation, Chinese Academy of Sciences (CASIA)](http://www.ia.cas.cn/), focusing on visual object tracking, visual language tracking and AI4Science.
- **Dailing Zhang**, Ph.D. student at the [Institute of Automation, Chinese Academy of Sciences (CASIA)](http://www.ia.cas.cn/), focusing on visual object tracking, visual language tracking and AI4Science.
- - [**Jiahui Gao**](https://sumilergao.github.io/jiahuig.hku/), Ph.D. at the [University of Hong Kong (HKU)](https://www.hku.hk/), focusing on natural language processing, including Pre-trained Language Modeling (PLM), Automatic Machining Learning (AutoML), and Multi-Modal (vision-language) learning.
- **Yanyao Zhou**, Ph.D. student at the [University of Hong Kong (HKU)](https://www.hku.hk/), focusing on cognitive science and psychology.
- **Yiping Ma**, Ph.D. student at the [East China Normal University](https://www.ecnu.edu.cn/), focusing on intelligent education technique and human-computer interaction.

<!--# ğŸ’» Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.-->
